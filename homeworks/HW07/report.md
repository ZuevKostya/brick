# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
S07-hw-dataset-01.csv, 
S07-hw-dataset-02.csv, 
S07-hw-dataset-03.csv
### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы / шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы + лишний шумовой признак.


### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: scaling StandardScaler, imputation mean, encoding get_dummies
- Поиск гиперпараметров:
  - KMeans: k = {2..10}, фиксировали random_state=42, n_init=10. 
  DBSCAN: eps = {0.3..1.5} (шаг 0.1), min_samples = {3..10}.
  - Критерий выбора: максимальный silhouette; при близких значениях учитывали меньший Davies-Bouldin и разумный Calinski-Harabasz.
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)исключали шум -1
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами) PCA n_components=2, random_state=42; t-SNE perplexity=30

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans: подбор количества кластеров k = {2..10}, random_state=42, n_init=10.
- DBSCAN: подбор eps = {0.3..1.5} и min_samples = {3..10}; анализ доли шума.


## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans k=2
Метрики (silhouette / DB / CH): 0.522 / 0.685 / 11786.95. 
Если был DBSCAN: доля шума ≈ 0.00067; метрики хуже (silhouette ≈ 0.384). 
Коротко: KMeans хорошо разделяет два компактных кластера при стандартизации; DBSCAN почти не отсеивает шум, но теряет качество из-за глобальной структуры.

### 4.2 Dataset B

Лучший метод и параметры: DBSCAN (eps=0.7, min_samples=3, n_clusters=2).
Метрики (silhouette / DB / CH):  0.346 / 0.551 / 10.41.
Если был DBSCAN: доля шума ≈ 0.0071 (разумная). KMeans в этом датасете уступает (silhouette ≈ 0.307), вероятно из-за различной плотности и шумовой координаты.
Коротко: почему это решение выглядит разумным именно для этого датасета: нелинейная структура, DBSCAN лучше KMeans

### 4.3 Dataset C

Лучший метод и параметры:  KMeans (k=3).
Метрики (silhouette / DB / CH): 0.316 / 1.158 / 6957.16.
Если был DBSCAN: доля шума и комментарий: 0.15, шум от разной плотности
Коротко: почему это решение выглядит разумным именно для этого датасета: разная плотность, DBSCAN справился

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?На данных с неоднородной плотностью и вытянутыми формами; требует равных дисперсий и сферических кластеров.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?На данных с естественными плотностями (Dataset B): устойчив к шуму, не требует заранее знать k.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?Масштабирование и наличие шумовых/коррелированных признаков; без стандартизации silhouette заметно хуже, шумовые координаты сбивают KMeans.

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход): 5 запусков KMeans (k=4) на Dataset A с разными random_state.
- Результат: ARI между всеми парами запусков ≈ 1.000 (mean=1.000, std=0.000).
- Вывод: устойчиво (ARI>0.9). Итерации сходятся к одному разбиению благодаря чёткой структуре и стандартизации.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) **или**
  - любая другая логичная интерпретация.Средние по кластерам показывают различия в шкалах
- 3-6 строк выводов. Кластер 0:  признаки с крупным масштабом и шумовые координаты требуют стандартизации и/или методов, устойчивых к шуму; визуализация PCA помогает объяснять разбиения.

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.
1)Нужен предпроцессинг.
2)Метрики и визуализация важны.
3)DBSCAN хорошо работает с шумом.
4)Устойчивость можно проверять изменяя seed.ARI между запусками подтверждает надёжность результата.
5)Протокол позволяет эксперименту оставатся честным.
6)PCA-визуализации помогают интерпретировать кластеры, но не заменяют метрики.